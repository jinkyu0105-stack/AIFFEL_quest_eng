{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2197a8d-2cdd-4508-991b-be9bf46ad177",
   "metadata": {},
   "source": [
    "### 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4528907c-e711-468a-8f67-5f3174449e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3966ade-f4ee-40cd-b066-68eb4ed37af6",
   "metadata": {},
   "source": [
    "### 데이터 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39c06daf-fb57-4f6e-8c78-4dde4d3a775b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "submission = pd.read_csv(\"data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad33361-2070-4dec-a350-51d3b3c6da83",
   "metadata": {},
   "source": [
    "### date 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e5991fe-f6b7-44c2-b6b5-13b7d408ad29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['date'] = train['date'].astype(str)\n",
    "test['date'] = test['date'].astype(str)\n",
    "\n",
    "def process_date(df):\n",
    "    df['year'] = df['date'].str[:4].astype(int)\n",
    "    df['month'] = df['date'].str[4:6].astype(int)\n",
    "    df['year_month'] = (df['year'] - 2000) * 12 + df['month']\n",
    "    return df\n",
    "\n",
    "train = process_date(train)\n",
    "test = process_date(test)\n",
    "\n",
    "train = train.drop('date', axis=1)\n",
    "test = test.drop('date', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5170d7e-56fc-436a-88b8-3921e4d2f08c",
   "metadata": {},
   "source": [
    "### target 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d391a38-eb1a-471f-b0dd-8d3ea6c08577",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train[\"price\"]\n",
    "train = train.drop(\"price\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8b6227-4bdc-46fb-b97a-ea5c7b83eb9c",
   "metadata": {},
   "source": [
    "### id 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43c03552-009b-472d-8650-ec76961106d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(\"id\", axis=1)\n",
    "test = test.drop(\"id\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61eba9d3-828c-4fc1-9487-0913bbda4b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Feature Engineering =====\n",
    "train['building_age'] = train['year'] - train['yr_built']\n",
    "test['building_age'] = test['year'] - test['yr_built']\n",
    "\n",
    "train['was_renovated'] = (train['yr_renovated'] > 0).astype(int)\n",
    "test['was_renovated'] = (test['yr_renovated'] > 0).astype(int)\n",
    "\n",
    "train['living_ratio'] = train['sqft_living'] / (train['sqft_lot'] + 1)\n",
    "test['living_ratio'] = test['sqft_living'] / (test['sqft_lot'] + 1)\n",
    "\n",
    "train['basement_ratio'] = train['sqft_basement'] / (train['sqft_living'] + 1)\n",
    "test['basement_ratio'] = test['sqft_basement'] / (test['sqft_living'] + 1)\n",
    "\n",
    "train['sqft_per_bedroom'] = train['sqft_living'] / (train['bedrooms'] + 1)\n",
    "test['sqft_per_bedroom'] = test['sqft_living'] / (test['bedrooms'] + 1)\n",
    "# ==============================\n",
    "\n",
    "# zipcode를 categorical로 처리\n",
    "train['zipcode'] = train['zipcode'].astype('category')\n",
    "test['zipcode'] = test['zipcode'].astype('category')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd03b994-d71c-4a42-9c1e-df8e59fdc694",
   "metadata": {},
   "source": [
    "### target log 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10a55be8-4cdd-4227-984c-16dc57d8fb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log1p(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82a6510c-6705-4ded-b011-9e36a811381c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_test, y_pred):\n",
    "    return np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23913d4d-9aef-4dde-9365-79ea7eee5e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=2020\n",
    "\n",
    "gboost = GradientBoostingRegressor(random_state=random_state)\n",
    "xgboost = XGBRegressor(random_state=random_state)\n",
    "lightgbm = LGBMRegressor(random_state=random_state)\n",
    "rdforest = RandomForestRegressor(random_state=random_state)\n",
    "\n",
    "models = [gboost, xgboost, lightgbm, rdforest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de767922-64a9-414d-8ab8-63d11ff6cb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'num_leaves': [31, 63, 127],\n",
    "    'learning_rate': [0.05, 0.03],\n",
    "    'max_depth': [-1, 10, 15],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fc2b28e-9ab9-41e3-8477-782366229648",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMRegressor(random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9949171-413e-41a4-bd7c-a1b9b9b275ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8efa06ea-6bc8-4a96-a31c-468c8e953196",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001811 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3197\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.047779\n",
      "Fold 1 RMSE: 111720.41568\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001501 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3197\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.051002\n",
      "Fold 2 RMSE: 117952.85429\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001468 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3226\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.049303\n",
      "Fold 3 RMSE: 112036.26478\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3198\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.045028\n",
      "Fold 4 RMSE: 124759.65612\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004366 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.047499\n",
      "Fold 5 RMSE: 143688.26823\n",
      "\n",
      "CV RMSE mean: 122031.49182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(122031.49181861125)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_cv_rmse(model, X, y):\n",
    "    rmse_list = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(X)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "        score = rmse(y_val, y_pred)\n",
    "        rmse_list.append(score)\n",
    "\n",
    "        print(f\"Fold {fold + 1} RMSE: {score:.5f}\")\n",
    "\n",
    "    print(f\"\\nCV RMSE mean: {np.mean(rmse_list):.5f}\")\n",
    "    return np.mean(rmse_list)\n",
    "\n",
    "get_cv_rmse(model, train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72d76d51-7ab9-4790-b7cf-8dfb3425d211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_GridSearch(model, train, y, param_grid, verbose=2, n_jobs=5):\n",
    "    # GridSearchCV 모델로 초기화\n",
    "    grid_model = GridSearchCV(model, param_grid=param_grid, scoring='neg_mean_squared_error', \\\n",
    "                              cv=5, verbose=verbose, n_jobs=n_jobs)\n",
    "\n",
    "    # 모델 fitting\n",
    "    grid_model.fit(train, y)\n",
    "\n",
    "    # 결과값 저장\n",
    "    params = grid_model.cv_results_['params']\n",
    "    score = grid_model.cv_results_['mean_test_score']\n",
    "\n",
    "    # 데이터 프레임 생성\n",
    "    results = pd.DataFrame(params)\n",
    "    results['score'] = score\n",
    "\n",
    "    # RMSLE 값 계산 후 정렬\n",
    "    results['RMSLE'] = np.sqrt(-1 * results['score'])\n",
    "    results = results.sort_values('RMSLE')\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66f93262-27d4-4e05-944d-082d269108d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020350 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3195\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050187\n",
      "[CV] END ....learning_rate=0.05, max_depth=-1, num_leaves=31; total time=   2.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3226\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.052839\n",
      "[CV] END ....learning_rate=0.05, max_depth=-1, num_leaves=63; total time=   3.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002512 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3197\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.035255\n",
      "[CV] END ...learning_rate=0.05, max_depth=-1, num_leaves=127; total time=   5.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011053 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.051670\n",
      "[CV] END ....learning_rate=0.05, max_depth=10, num_leaves=31; total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008745 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3226\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.052839\n",
      "[CV] END ....learning_rate=0.05, max_depth=10, num_leaves=63; total time=   3.0s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014060 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3226\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.052839\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END ...learning_rate=0.05, max_depth=10, num_leaves=127; total time=   4.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021717 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3226\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.052839\n",
      "[CV] END ....learning_rate=0.05, max_depth=15, num_leaves=31; total time=   2.6s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002664 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.051670\n",
      "[CV] END ....learning_rate=0.05, max_depth=15, num_leaves=63; total time=   3.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006601 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3226\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.052839\n",
      "[CV] END ...learning_rate=0.05, max_depth=15, num_leaves=127; total time=   4.9s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002536 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3226\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.052839\n",
      "[CV] END ....learning_rate=0.03, max_depth=-1, num_leaves=31; total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008194 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3195\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050187\n",
      "[CV] END ....learning_rate=0.03, max_depth=-1, num_leaves=63; total time=   2.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3195\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050187\n",
      "[CV] END ...learning_rate=0.03, max_depth=-1, num_leaves=127; total time=   6.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010702 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3226\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.052839\n",
      "[CV] END ....learning_rate=0.03, max_depth=10, num_leaves=31; total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002850 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3195\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050187\n",
      "[CV] END ....learning_rate=0.03, max_depth=10, num_leaves=63; total time=   3.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006699 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3195\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050187\n",
      "[CV] END ...learning_rate=0.03, max_depth=10, num_leaves=127; total time=   5.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002657 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3226[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3226\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.052839\n",
      "[CV] END ....learning_rate=0.05, max_depth=-1, num_leaves=31; total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.051670\n",
      "[CV] END ....learning_rate=0.05, max_depth=-1, num_leaves=63; total time=   3.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014120 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.051670\n",
      "[CV] END ...learning_rate=0.05, max_depth=-1, num_leaves=127; total time=   6.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3195\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050187\n",
      "[CV] END ....learning_rate=0.05, max_depth=10, num_leaves=63; total time=   3.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005084 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3195\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050187\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END ...learning_rate=0.05, max_depth=10, num_leaves=127; total time=   4.8s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011732 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3195\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050187\n",
      "[CV] END ....learning_rate=0.05, max_depth=15, num_leaves=31; total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002390 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3197\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.035255\n",
      "[CV] END ....learning_rate=0.05, max_depth=15, num_leaves=31; total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019041 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3231\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050660\n",
      "[CV] END ....learning_rate=0.05, max_depth=15, num_leaves=63; total time=   3.6s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010688 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3231\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050660\n",
      "[CV] END ...learning_rate=0.05, max_depth=15, num_leaves=127; total time=   5.0s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017254 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3231\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050660\n",
      "[CV] END ....learning_rate=0.03, max_depth=-1, num_leaves=31; total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013569 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3231\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050660\n",
      "[CV] END ....learning_rate=0.03, max_depth=-1, num_leaves=63; total time=   2.6s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006685 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3226\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.052839\n",
      "[CV] END ...learning_rate=0.03, max_depth=-1, num_leaves=127; total time=   5.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005514 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3195\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050187\n",
      "[CV] END ....learning_rate=0.03, max_depth=10, num_leaves=31; total time=   2.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002655 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3226\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.052839\n",
      "[CV] END ....learning_rate=0.03, max_depth=10, num_leaves=63; total time=   3.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009214 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3226\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.052839\n",
      "[CV] END ...learning_rate=0.03, max_depth=10, num_leaves=127; total time=   5.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008682 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008899 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3231\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050660\n",
      "[CV] END ....learning_rate=0.05, max_depth=-1, num_leaves=31; total time=   2.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3195\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050187\n",
      "[CV] END ....learning_rate=0.05, max_depth=-1, num_leaves=63; total time=   3.0s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009594 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3195\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050187\n",
      "[CV] END ...learning_rate=0.05, max_depth=-1, num_leaves=127; total time=   5.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002683 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3195\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050187\n",
      "[CV] END ....learning_rate=0.05, max_depth=10, num_leaves=31; total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3197\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.035255\n",
      "[CV] END ....learning_rate=0.05, max_depth=10, num_leaves=31; total time=   2.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010480 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3197\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.035255\n",
      "[CV] END ....learning_rate=0.05, max_depth=10, num_leaves=63; total time=   3.0s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3197\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.035255\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END ...learning_rate=0.05, max_depth=10, num_leaves=127; total time=   4.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016804 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3231\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050660\n",
      "[CV] END ....learning_rate=0.05, max_depth=15, num_leaves=31; total time=   2.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3197\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.035255\n",
      "[CV] END ....learning_rate=0.05, max_depth=15, num_leaves=63; total time=   3.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013920 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3197\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.035255\n",
      "[CV] END ...learning_rate=0.05, max_depth=15, num_leaves=127; total time=   5.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012214 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3226\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.052839\n",
      "[CV] END ....learning_rate=0.03, max_depth=-1, num_leaves=63; total time=   3.8s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003055 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.051670\n",
      "[CV] END ...learning_rate=0.03, max_depth=-1, num_leaves=127; total time=   5.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005860 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.051670\n",
      "[CV] END ....learning_rate=0.03, max_depth=10, num_leaves=31; total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022105 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.051670\n",
      "[CV] END ....learning_rate=0.03, max_depth=10, num_leaves=63; total time=   3.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004883 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.051670\n",
      "[CV] END ...learning_rate=0.03, max_depth=10, num_leaves=127; total time=   4.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012301 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3195\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050187\n",
      "[CV] END ....learning_rate=0.03, max_depth=15, num_leaves=31; total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002645 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3195\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050187\n",
      "[CV] END ....learning_rate=0.03, max_depth=15, num_leaves=63; total time=   2.9s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011852 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3197\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.035255\n",
      "[CV] END ....learning_rate=0.05, max_depth=-1, num_leaves=31; total time=   2.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006413 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3197\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.035255\n",
      "[CV] END ....learning_rate=0.05, max_depth=-1, num_leaves=63; total time=   3.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041300 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3231\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050660\n",
      "[CV] END ...learning_rate=0.05, max_depth=-1, num_leaves=127; total time=   5.8s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002620 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3231\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050660\n",
      "[CV] END ....learning_rate=0.05, max_depth=10, num_leaves=31; total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005925 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3231\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050660\n",
      "[CV] END ....learning_rate=0.05, max_depth=10, num_leaves=63; total time=   3.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006573 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3231\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050660\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END ...learning_rate=0.05, max_depth=10, num_leaves=127; total time=   4.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002594 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.051670\n",
      "[CV] END ....learning_rate=0.05, max_depth=15, num_leaves=31; total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023522 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3226\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.052839\n",
      "[CV] END ....learning_rate=0.05, max_depth=15, num_leaves=63; total time=   3.6s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010955 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.051670\n",
      "[CV] END ...learning_rate=0.05, max_depth=15, num_leaves=127; total time=   5.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008370 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.051670\n",
      "[CV] END ....learning_rate=0.03, max_depth=-1, num_leaves=31; total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017425 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.051670\n",
      "[CV] END ....learning_rate=0.03, max_depth=-1, num_leaves=63; total time=   4.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028424 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3231\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050660\n",
      "[CV] END ...learning_rate=0.03, max_depth=-1, num_leaves=127; total time=   5.6s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010785 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3231\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050660\n",
      "[CV] END ....learning_rate=0.03, max_depth=10, num_leaves=31; total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006710 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3231\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050660\n",
      "[CV] END ....learning_rate=0.03, max_depth=10, num_leaves=63; total time=   3.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020350 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3231\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050660\n",
      "[CV] END ...learning_rate=0.03, max_depth=10, num_leaves=127; total time=   5.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022346 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3226\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.052839\n",
      "[CV] END ....learning_rate=0.03, max_depth=15, num_leaves=63; total time=   3.8s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004576 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014593 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.051670\n",
      "[CV] END ....learning_rate=0.05, max_depth=-1, num_leaves=31; total time=   2.6s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006868 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3231\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050660\n",
      "[CV] END ....learning_rate=0.05, max_depth=-1, num_leaves=63; total time=   2.9s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007203 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3226\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.052839\n",
      "[CV] END ...learning_rate=0.05, max_depth=-1, num_leaves=127; total time=   5.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016002 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3226\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.052839\n",
      "[CV] END ....learning_rate=0.05, max_depth=10, num_leaves=31; total time=   2.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.051670\n",
      "[CV] END ....learning_rate=0.05, max_depth=10, num_leaves=63; total time=   2.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019329 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.051670\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END ...learning_rate=0.05, max_depth=10, num_leaves=127; total time=   5.6s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005668 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3195\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050187\n",
      "[CV] END ....learning_rate=0.05, max_depth=15, num_leaves=63; total time=   2.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010736 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3195\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050187\n",
      "[CV] END ...learning_rate=0.05, max_depth=15, num_leaves=127; total time=   5.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011937 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3195\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050187\n",
      "[CV] END ....learning_rate=0.03, max_depth=-1, num_leaves=31; total time=   2.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003935 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3197\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.035255\n",
      "[CV] END ....learning_rate=0.03, max_depth=-1, num_leaves=31; total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018266 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3197\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.035255\n",
      "[CV] END ....learning_rate=0.03, max_depth=-1, num_leaves=63; total time=   4.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009533 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3197\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.035255\n",
      "[CV] END ...learning_rate=0.03, max_depth=-1, num_leaves=127; total time=   4.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027195 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3197\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.035255\n",
      "[CV] END ....learning_rate=0.03, max_depth=10, num_leaves=31; total time=   2.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006449 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3197\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.035255\n",
      "[CV] END ....learning_rate=0.03, max_depth=10, num_leaves=63; total time=   3.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018498 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3197\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.035255\n",
      "[CV] END ...learning_rate=0.03, max_depth=10, num_leaves=127; total time=   5.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.051670\n",
      "[CV] END ....learning_rate=0.03, max_depth=15, num_leaves=63; total time=   4.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006769 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3230"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/numpy/ma/core.py:2892: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002081 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3237\n",
      "[LightGBM] [Info] Number of data points in the train set: 15035, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.048122\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>score</th>\n",
       "      <th>RMSLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.05</td>\n",
       "      <td>-1</td>\n",
       "      <td>127</td>\n",
       "      <td>-0.027009</td>\n",
       "      <td>0.164343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.05</td>\n",
       "      <td>15</td>\n",
       "      <td>127</td>\n",
       "      <td>-0.027061</td>\n",
       "      <td>0.164502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>127</td>\n",
       "      <td>-0.027223</td>\n",
       "      <td>0.164994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.05</td>\n",
       "      <td>15</td>\n",
       "      <td>63</td>\n",
       "      <td>-0.027289</td>\n",
       "      <td>0.165195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>-1</td>\n",
       "      <td>63</td>\n",
       "      <td>-0.027384</td>\n",
       "      <td>0.165481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>63</td>\n",
       "      <td>-0.027421</td>\n",
       "      <td>0.165593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.05</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.028300</td>\n",
       "      <td>0.168225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>-1</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.028301</td>\n",
       "      <td>0.168228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.028328</td>\n",
       "      <td>0.168309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.03</td>\n",
       "      <td>-1</td>\n",
       "      <td>127</td>\n",
       "      <td>-0.029847</td>\n",
       "      <td>0.172762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.03</td>\n",
       "      <td>15</td>\n",
       "      <td>127</td>\n",
       "      <td>-0.029849</td>\n",
       "      <td>0.172769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.03</td>\n",
       "      <td>10</td>\n",
       "      <td>127</td>\n",
       "      <td>-0.029874</td>\n",
       "      <td>0.172842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.03</td>\n",
       "      <td>15</td>\n",
       "      <td>63</td>\n",
       "      <td>-0.030794</td>\n",
       "      <td>0.175482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.03</td>\n",
       "      <td>-1</td>\n",
       "      <td>63</td>\n",
       "      <td>-0.030794</td>\n",
       "      <td>0.175482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.03</td>\n",
       "      <td>10</td>\n",
       "      <td>63</td>\n",
       "      <td>-0.030834</td>\n",
       "      <td>0.175596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.03</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.032424</td>\n",
       "      <td>0.180067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.03</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.032429</td>\n",
       "      <td>0.180081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.03</td>\n",
       "      <td>-1</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.032429</td>\n",
       "      <td>0.180081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    learning_rate  max_depth  num_leaves     score     RMSLE\n",
       "2            0.05         -1         127 -0.027009  0.164343\n",
       "8            0.05         15         127 -0.027061  0.164502\n",
       "5            0.05         10         127 -0.027223  0.164994\n",
       "7            0.05         15          63 -0.027289  0.165195\n",
       "1            0.05         -1          63 -0.027384  0.165481\n",
       "4            0.05         10          63 -0.027421  0.165593\n",
       "6            0.05         15          31 -0.028300  0.168225\n",
       "0            0.05         -1          31 -0.028301  0.168228\n",
       "3            0.05         10          31 -0.028328  0.168309\n",
       "11           0.03         -1         127 -0.029847  0.172762\n",
       "17           0.03         15         127 -0.029849  0.172769\n",
       "14           0.03         10         127 -0.029874  0.172842\n",
       "16           0.03         15          63 -0.030794  0.175482\n",
       "10           0.03         -1          63 -0.030794  0.175482\n",
       "13           0.03         10          63 -0.030834  0.175596\n",
       "12           0.03         10          31 -0.032424  0.180067\n",
       "15           0.03         15          31 -0.032429  0.180081\n",
       "9            0.03         -1          31 -0.032429  0.180081"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_GridSearch(model, train, y, param_grid, verbose=2, n_jobs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "813debc8-66df-4dba-ae4e-7a6ec30c17ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMRegressor(\n",
    "    n_estimators=3000,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=64,\n",
    "    max_depth=-1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.1,\n",
    "    random_state=random_state\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a2a39a8-616b-48c0-b8b1-34dd19908c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== XGB용 데이터 (category 제거) =====\n",
    "train_xgb = train.copy()\n",
    "test_xgb = test.copy()\n",
    "\n",
    "train_xgb['zipcode'] = train_xgb['zipcode'].astype(int)\n",
    "test_xgb['zipcode'] = test_xgb['zipcode'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "813b0db3-d2dd-48b4-8a8b-95f38f639225",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=500,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=random_state,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74e7e4e9-cdda-44f3-9a31-0ddade17f8a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002488 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3237\n",
      "[LightGBM] [Info] Number of data points in the train set: 15035, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.048122\n"
     ]
    }
   ],
   "source": [
    "# ===== Ensemble Training =====\n",
    "\n",
    "# LGBM\n",
    "lgbm_model = model\n",
    "\n",
    "lgbm_model.fit(train, y)\n",
    "xgb_model.fit(train_xgb, y)\n",
    "\n",
    "lgbm_pred = lgbm_model.predict(test)\n",
    "xgb_pred = xgb_model.predict(test_xgb)\n",
    "\n",
    "# 가중 평균 (안전한 기본값)\n",
    "ensemble_pred = 0.6 * lgbm_pred + 0.4 * xgb_pred\n",
    "\n",
    "# log -> 원래 price\n",
    "ensemble_pred = np.expm1(ensemble_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09ecd1ce-f777-417c-bd3c-abe1a3db7f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble submission saved!\n"
     ]
    }
   ],
   "source": [
    "submission = pd.read_csv(\"data/sample_submission.csv\")\n",
    "submission['price'] = ensemble_pred\n",
    "\n",
    "submission.to_csv(\n",
    "    \"data/ensemble_submission_lgbm_xgb.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"Ensemble submission saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1619739-30ea-4eb2-9457-30017ba6cf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_submission(model, train, y, test, model_name, rmsle=None):\n",
    "    model.fit(train, y)\n",
    "    prediction = model.predict(test)\n",
    "    prediction = np.expm1(prediction)\n",
    "    data_dir = '~/work/kaggle_kakr_housing/data'\n",
    "    submission_path = join(data_dir, 'sample_submission.csv')\n",
    "    submission = pd.read_csv(submission_path)\n",
    "    submission['price'] = prediction\n",
    "    submission_csv_path = '{}/submission_{}_RMSLE_{}.csv'.format(data_dir, model_name, rmsle)\n",
    "    submission.to_csv(submission_csv_path, index=False)\n",
    "    print('{} saved!'.format(submission_csv_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86e60e6d-a7fb-4ee0-9fc3-d3a087b61354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os \n",
    "# from os.path import join\n",
    "# save_submission(model, train, y, test, 'lgbm', rmsle='4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
