{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2197a8d-2cdd-4508-991b-be9bf46ad177",
   "metadata": {},
   "source": [
    "### 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4528907c-e711-468a-8f67-5f3174449e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3966ade-f4ee-40cd-b066-68eb4ed37af6",
   "metadata": {},
   "source": [
    "### 데이터 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39c06daf-fb57-4f6e-8c78-4dde4d3a775b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "submission = pd.read_csv(\"data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad33361-2070-4dec-a350-51d3b3c6da83",
   "metadata": {},
   "source": [
    "### date 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e5991fe-f6b7-44c2-b6b5-13b7d408ad29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['date'] = train['date'].astype(str)\n",
    "test['date'] = test['date'].astype(str)\n",
    "\n",
    "def process_date(df):\n",
    "    df['year'] = df['date'].str[:4].astype(int)\n",
    "    df['month'] = df['date'].str[4:6].astype(int)\n",
    "    df['year_month'] = (df['year'] - 2000) * 12 + df['month']\n",
    "    return df\n",
    "\n",
    "train = process_date(train)\n",
    "test = process_date(test)\n",
    "\n",
    "train = train.drop('date', axis=1)\n",
    "test = test.drop('date', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5170d7e-56fc-436a-88b8-3921e4d2f08c",
   "metadata": {},
   "source": [
    "### target 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d391a38-eb1a-471f-b0dd-8d3ea6c08577",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train[\"price\"]\n",
    "train = train.drop(\"price\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8b6227-4bdc-46fb-b97a-ea5c7b83eb9c",
   "metadata": {},
   "source": [
    "### id 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43c03552-009b-472d-8650-ec76961106d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(\"id\", axis=1)\n",
    "test = test.drop(\"id\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61eba9d3-828c-4fc1-9487-0913bbda4b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Feature Engineering =====\n",
    "train['building_age'] = train['year'] - train['yr_built']\n",
    "test['building_age'] = test['year'] - test['yr_built']\n",
    "\n",
    "train['was_renovated'] = (train['yr_renovated'] > 0).astype(int)\n",
    "test['was_renovated'] = (test['yr_renovated'] > 0).astype(int)\n",
    "\n",
    "train['living_ratio'] = train['sqft_living'] / (train['sqft_lot'] + 1)\n",
    "test['living_ratio'] = test['sqft_living'] / (test['sqft_lot'] + 1)\n",
    "\n",
    "train['basement_ratio'] = train['sqft_basement'] / (train['sqft_living'] + 1)\n",
    "test['basement_ratio'] = test['sqft_basement'] / (test['sqft_living'] + 1)\n",
    "\n",
    "train['sqft_per_bedroom'] = train['sqft_living'] / (train['bedrooms'] + 1)\n",
    "test['sqft_per_bedroom'] = test['sqft_living'] / (test['bedrooms'] + 1)\n",
    "# ==============================\n",
    "\n",
    "# zipcode를 categorical로 처리\n",
    "train['zipcode'] = train['zipcode'].astype('category')\n",
    "test['zipcode'] = test['zipcode'].astype('category')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd03b994-d71c-4a42-9c1e-df8e59fdc694",
   "metadata": {},
   "source": [
    "### target log 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10a55be8-4cdd-4227-984c-16dc57d8fb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log1p(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82a6510c-6705-4ded-b011-9e36a811381c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_test, y_pred):\n",
    "    return np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23913d4d-9aef-4dde-9365-79ea7eee5e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=2020\n",
    "\n",
    "gboost = GradientBoostingRegressor(random_state=random_state)\n",
    "xgboost = XGBRegressor(random_state=random_state)\n",
    "lightgbm = LGBMRegressor(random_state=random_state)\n",
    "rdforest = RandomForestRegressor(random_state=random_state)\n",
    "\n",
    "models = [gboost, xgboost, lightgbm, rdforest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de767922-64a9-414d-8ab8-63d11ff6cb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'num_leaves': [31, 63, 127],\n",
    "    'learning_rate': [0.05, 0.03],\n",
    "    'max_depth': [-1, 10, 15],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fc2b28e-9ab9-41e3-8477-782366229648",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMRegressor(random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9949171-413e-41a4-bd7c-a1b9b9b275ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8efa06ea-6bc8-4a96-a31c-468c8e953196",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001811 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3197\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.047779\n",
      "Fold 1 RMSE: 111720.41568\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001501 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3197\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.051002\n",
      "Fold 2 RMSE: 117952.85429\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001468 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3226\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.049303\n",
      "Fold 3 RMSE: 112036.26478\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3198\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.045028\n",
      "Fold 4 RMSE: 124759.65612\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004366 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.047499\n",
      "Fold 5 RMSE: 143688.26823\n",
      "\n",
      "CV RMSE mean: 122031.49182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(122031.49181861125)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_cv_rmse(model, X, y):\n",
    "    rmse_list = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(X)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "        score = rmse(y_val, y_pred)\n",
    "        rmse_list.append(score)\n",
    "\n",
    "        print(f\"Fold {fold + 1} RMSE: {score:.5f}\")\n",
    "\n",
    "    print(f\"\\nCV RMSE mean: {np.mean(rmse_list):.5f}\")\n",
    "    return np.mean(rmse_list)\n",
    "\n",
    "get_cv_rmse(model, train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72d76d51-7ab9-4790-b7cf-8dfb3425d211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_GridSearch(model, train, y, param_grid, verbose=2, n_jobs=5):\n",
    "    # GridSearchCV 모델로 초기화\n",
    "    grid_model = GridSearchCV(model, param_grid=param_grid, scoring='neg_mean_squared_error', \\\n",
    "                              cv=5, verbose=verbose, n_jobs=n_jobs)\n",
    "\n",
    "    # 모델 fitting\n",
    "    grid_model.fit(train, y)\n",
    "\n",
    "    # 결과값 저장\n",
    "    params = grid_model.cv_results_['params']\n",
    "    score = grid_model.cv_results_['mean_test_score']\n",
    "\n",
    "    # 데이터 프레임 생성\n",
    "    results = pd.DataFrame(params)\n",
    "    results['score'] = score\n",
    "\n",
    "    # RMSLE 값 계산 후 정렬\n",
    "    results['RMSLE'] = np.sqrt(-1 * results['score'])\n",
    "    results = results.sort_values('RMSLE')\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66f93262-27d4-4e05-944d-082d269108d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020350 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3195\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050187\n",
      "[CV] END ....learning_rate=0.05, max_depth=-1, num_leaves=31; total time=   2.5s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3226\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.052839\n",
      "[CV] END ....learning_rate=0.05, max_depth=-1, num_leaves=63; total time=   3.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002512 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3197\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.035255\n",
      "[CV] END ...learning_rate=0.05, max_depth=-1, num_leaves=127; total time=   5.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011053 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.051670\n",
      "[CV] END ....learning_rate=0.05, max_depth=10, num_leaves=31; total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008745 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3226\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.052839\n",
      "[CV] END ....learning_rate=0.05, max_depth=10, num_leaves=63; total time=   3.0s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014060 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3226\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.052839\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END ...learning_rate=0.05, max_depth=10, num_leaves=127; total time=   4.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021717 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3226\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.052839\n",
      "[CV] END ....learning_rate=0.05, max_depth=15, num_leaves=31; total time=   2.6s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002664 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.051670\n",
      "[CV] END ....learning_rate=0.05, max_depth=15, num_leaves=63; total time=   3.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006601 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3226\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.052839\n",
      "[CV] END ...learning_rate=0.05, max_depth=15, num_leaves=127; total time=   4.9s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002536 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3226\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.052839\n",
      "[CV] END ....learning_rate=0.03, max_depth=-1, num_leaves=31; total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008194 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3195\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050187\n",
      "[CV] END ....learning_rate=0.03, max_depth=-1, num_leaves=63; total time=   2.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3195\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050187\n",
      "[CV] END ...learning_rate=0.03, max_depth=-1, num_leaves=127; total time=   6.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010702 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3226\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.052839\n",
      "[CV] END ....learning_rate=0.03, max_depth=10, num_leaves=31; total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002850 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3195\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050187\n",
      "[CV] END ....learning_rate=0.03, max_depth=10, num_leaves=63; total time=   3.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006699 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3195\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050187\n",
      "[CV] END ...learning_rate=0.03, max_depth=10, num_leaves=127; total time=   5.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002657 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3226[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3226\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.052839\n",
      "[CV] END ....learning_rate=0.05, max_depth=-1, num_leaves=31; total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.051670\n",
      "[CV] END ....learning_rate=0.05, max_depth=-1, num_leaves=63; total time=   3.2s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014120 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.051670\n",
      "[CV] END ...learning_rate=0.05, max_depth=-1, num_leaves=127; total time=   6.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3195\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050187\n",
      "[CV] END ....learning_rate=0.05, max_depth=10, num_leaves=63; total time=   3.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005084 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3195\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050187\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END ...learning_rate=0.05, max_depth=10, num_leaves=127; total time=   4.8s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011732 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3195\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050187\n",
      "[CV] END ....learning_rate=0.05, max_depth=15, num_leaves=31; total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002390 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3197\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.035255\n",
      "[CV] END ....learning_rate=0.05, max_depth=15, num_leaves=31; total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019041 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3231\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050660\n",
      "[CV] END ....learning_rate=0.05, max_depth=15, num_leaves=63; total time=   3.6s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010688 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3231\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050660\n",
      "[CV] END ...learning_rate=0.05, max_depth=15, num_leaves=127; total time=   5.0s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017254 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3231\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050660\n",
      "[CV] END ....learning_rate=0.03, max_depth=-1, num_leaves=31; total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013569 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3231\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050660\n",
      "[CV] END ....learning_rate=0.03, max_depth=-1, num_leaves=63; total time=   2.6s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006685 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3226\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.052839\n",
      "[CV] END ...learning_rate=0.03, max_depth=-1, num_leaves=127; total time=   5.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005514 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3195\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050187\n",
      "[CV] END ....learning_rate=0.03, max_depth=10, num_leaves=31; total time=   2.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002655 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3226\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.052839\n",
      "[CV] END ....learning_rate=0.03, max_depth=10, num_leaves=63; total time=   3.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009214 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3226\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.052839\n",
      "[CV] END ...learning_rate=0.03, max_depth=10, num_leaves=127; total time=   5.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008682 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008899 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3231\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050660\n",
      "[CV] END ....learning_rate=0.05, max_depth=-1, num_leaves=31; total time=   2.5s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3195\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050187\n",
      "[CV] END ....learning_rate=0.05, max_depth=-1, num_leaves=63; total time=   3.0s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009594 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3195\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050187\n",
      "[CV] END ...learning_rate=0.05, max_depth=-1, num_leaves=127; total time=   5.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002683 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3195\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050187\n",
      "[CV] END ....learning_rate=0.05, max_depth=10, num_leaves=31; total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3197\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.035255\n",
      "[CV] END ....learning_rate=0.05, max_depth=10, num_leaves=31; total time=   2.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010480 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3197\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.035255\n",
      "[CV] END ....learning_rate=0.05, max_depth=10, num_leaves=63; total time=   3.0s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3197\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.035255\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END ...learning_rate=0.05, max_depth=10, num_leaves=127; total time=   4.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016804 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3231\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050660\n",
      "[CV] END ....learning_rate=0.05, max_depth=15, num_leaves=31; total time=   2.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3197\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.035255\n",
      "[CV] END ....learning_rate=0.05, max_depth=15, num_leaves=63; total time=   3.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013920 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3197\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.035255\n",
      "[CV] END ...learning_rate=0.05, max_depth=15, num_leaves=127; total time=   5.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012214 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3226\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.052839\n",
      "[CV] END ....learning_rate=0.03, max_depth=-1, num_leaves=63; total time=   3.8s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003055 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.051670\n",
      "[CV] END ...learning_rate=0.03, max_depth=-1, num_leaves=127; total time=   5.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005860 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.051670\n",
      "[CV] END ....learning_rate=0.03, max_depth=10, num_leaves=31; total time=   2.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022105 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.051670\n",
      "[CV] END ....learning_rate=0.03, max_depth=10, num_leaves=63; total time=   3.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004883 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.051670\n",
      "[CV] END ...learning_rate=0.03, max_depth=10, num_leaves=127; total time=   4.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012301 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3195\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050187\n",
      "[CV] END ....learning_rate=0.03, max_depth=15, num_leaves=31; total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002645 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3195\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050187\n",
      "[CV] END ....learning_rate=0.03, max_depth=15, num_leaves=63; total time=   2.9s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011852 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3197\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.035255\n",
      "[CV] END ....learning_rate=0.05, max_depth=-1, num_leaves=31; total time=   2.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006413 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3197\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.035255\n",
      "[CV] END ....learning_rate=0.05, max_depth=-1, num_leaves=63; total time=   3.1s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041300 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3231\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050660\n",
      "[CV] END ...learning_rate=0.05, max_depth=-1, num_leaves=127; total time=   5.8s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002620 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3231\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050660\n",
      "[CV] END ....learning_rate=0.05, max_depth=10, num_leaves=31; total time=   2.0s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005925 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3231\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050660\n",
      "[CV] END ....learning_rate=0.05, max_depth=10, num_leaves=63; total time=   3.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006573 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3231\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050660\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END ...learning_rate=0.05, max_depth=10, num_leaves=127; total time=   4.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002594 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.051670\n",
      "[CV] END ....learning_rate=0.05, max_depth=15, num_leaves=31; total time=   1.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023522 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3226\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.052839\n",
      "[CV] END ....learning_rate=0.05, max_depth=15, num_leaves=63; total time=   3.6s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010955 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.051670\n",
      "[CV] END ...learning_rate=0.05, max_depth=15, num_leaves=127; total time=   5.4s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008370 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.051670\n",
      "[CV] END ....learning_rate=0.03, max_depth=-1, num_leaves=31; total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017425 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.051670\n",
      "[CV] END ....learning_rate=0.03, max_depth=-1, num_leaves=63; total time=   4.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028424 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3231\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050660\n",
      "[CV] END ...learning_rate=0.03, max_depth=-1, num_leaves=127; total time=   5.6s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010785 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3231\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050660\n",
      "[CV] END ....learning_rate=0.03, max_depth=10, num_leaves=31; total time=   2.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006710 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3231\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050660\n",
      "[CV] END ....learning_rate=0.03, max_depth=10, num_leaves=63; total time=   3.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020350 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3231\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050660\n",
      "[CV] END ...learning_rate=0.03, max_depth=10, num_leaves=127; total time=   5.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022346 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3226\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.052839\n",
      "[CV] END ....learning_rate=0.03, max_depth=15, num_leaves=63; total time=   3.8s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004576 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014593 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.051670\n",
      "[CV] END ....learning_rate=0.05, max_depth=-1, num_leaves=31; total time=   2.6s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006868 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3231\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050660\n",
      "[CV] END ....learning_rate=0.05, max_depth=-1, num_leaves=63; total time=   2.9s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007203 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3226\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.052839\n",
      "[CV] END ...learning_rate=0.05, max_depth=-1, num_leaves=127; total time=   5.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016002 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3226\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.052839\n",
      "[CV] END ....learning_rate=0.05, max_depth=10, num_leaves=31; total time=   2.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.051670\n",
      "[CV] END ....learning_rate=0.05, max_depth=10, num_leaves=63; total time=   2.9s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019329 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.051670\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END ...learning_rate=0.05, max_depth=10, num_leaves=127; total time=   5.6s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005668 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3195\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050187\n",
      "[CV] END ....learning_rate=0.05, max_depth=15, num_leaves=63; total time=   2.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010736 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3195\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050187\n",
      "[CV] END ...learning_rate=0.05, max_depth=15, num_leaves=127; total time=   5.4s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011937 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3195\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.050187\n",
      "[CV] END ....learning_rate=0.03, max_depth=-1, num_leaves=31; total time=   2.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003935 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3197\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.035255\n",
      "[CV] END ....learning_rate=0.03, max_depth=-1, num_leaves=31; total time=   2.1s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018266 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3197\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.035255\n",
      "[CV] END ....learning_rate=0.03, max_depth=-1, num_leaves=63; total time=   4.3s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009533 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3197\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.035255\n",
      "[CV] END ...learning_rate=0.03, max_depth=-1, num_leaves=127; total time=   4.6s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027195 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3197\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.035255\n",
      "[CV] END ....learning_rate=0.03, max_depth=10, num_leaves=31; total time=   2.7s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006449 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3197\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.035255\n",
      "[CV] END ....learning_rate=0.03, max_depth=10, num_leaves=63; total time=   3.8s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018498 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3197\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.035255\n",
      "[CV] END ...learning_rate=0.03, max_depth=10, num_leaves=127; total time=   5.0s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3230\n",
      "[LightGBM] [Info] Number of data points in the train set: 12028, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.051670\n",
      "[CV] END ....learning_rate=0.03, max_depth=15, num_leaves=63; total time=   4.2s\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006769 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3230"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/numpy/ma/core.py:2892: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002081 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3237\n",
      "[LightGBM] [Info] Number of data points in the train set: 15035, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.048122\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>score</th>\n",
       "      <th>RMSLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.05</td>\n",
       "      <td>-1</td>\n",
       "      <td>127</td>\n",
       "      <td>-0.027009</td>\n",
       "      <td>0.164343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.05</td>\n",
       "      <td>15</td>\n",
       "      <td>127</td>\n",
       "      <td>-0.027061</td>\n",
       "      <td>0.164502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>127</td>\n",
       "      <td>-0.027223</td>\n",
       "      <td>0.164994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.05</td>\n",
       "      <td>15</td>\n",
       "      <td>63</td>\n",
       "      <td>-0.027289</td>\n",
       "      <td>0.165195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>-1</td>\n",
       "      <td>63</td>\n",
       "      <td>-0.027384</td>\n",
       "      <td>0.165481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>63</td>\n",
       "      <td>-0.027421</td>\n",
       "      <td>0.165593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.05</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.028300</td>\n",
       "      <td>0.168225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>-1</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.028301</td>\n",
       "      <td>0.168228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.028328</td>\n",
       "      <td>0.168309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.03</td>\n",
       "      <td>-1</td>\n",
       "      <td>127</td>\n",
       "      <td>-0.029847</td>\n",
       "      <td>0.172762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.03</td>\n",
       "      <td>15</td>\n",
       "      <td>127</td>\n",
       "      <td>-0.029849</td>\n",
       "      <td>0.172769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.03</td>\n",
       "      <td>10</td>\n",
       "      <td>127</td>\n",
       "      <td>-0.029874</td>\n",
       "      <td>0.172842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.03</td>\n",
       "      <td>15</td>\n",
       "      <td>63</td>\n",
       "      <td>-0.030794</td>\n",
       "      <td>0.175482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.03</td>\n",
       "      <td>-1</td>\n",
       "      <td>63</td>\n",
       "      <td>-0.030794</td>\n",
       "      <td>0.175482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.03</td>\n",
       "      <td>10</td>\n",
       "      <td>63</td>\n",
       "      <td>-0.030834</td>\n",
       "      <td>0.175596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.03</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.032424</td>\n",
       "      <td>0.180067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.03</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.032429</td>\n",
       "      <td>0.180081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.03</td>\n",
       "      <td>-1</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.032429</td>\n",
       "      <td>0.180081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    learning_rate  max_depth  num_leaves     score     RMSLE\n",
       "2            0.05         -1         127 -0.027009  0.164343\n",
       "8            0.05         15         127 -0.027061  0.164502\n",
       "5            0.05         10         127 -0.027223  0.164994\n",
       "7            0.05         15          63 -0.027289  0.165195\n",
       "1            0.05         -1          63 -0.027384  0.165481\n",
       "4            0.05         10          63 -0.027421  0.165593\n",
       "6            0.05         15          31 -0.028300  0.168225\n",
       "0            0.05         -1          31 -0.028301  0.168228\n",
       "3            0.05         10          31 -0.028328  0.168309\n",
       "11           0.03         -1         127 -0.029847  0.172762\n",
       "17           0.03         15         127 -0.029849  0.172769\n",
       "14           0.03         10         127 -0.029874  0.172842\n",
       "16           0.03         15          63 -0.030794  0.175482\n",
       "10           0.03         -1          63 -0.030794  0.175482\n",
       "13           0.03         10          63 -0.030834  0.175596\n",
       "12           0.03         10          31 -0.032424  0.180067\n",
       "15           0.03         15          31 -0.032429  0.180081\n",
       "9            0.03         -1          31 -0.032429  0.180081"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_GridSearch(model, train, y, param_grid, verbose=2, n_jobs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "813debc8-66df-4dba-ae4e-7a6ec30c17ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMRegressor(\n",
    "    n_estimators=3000,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=64,\n",
    "    max_depth=-1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.1,\n",
    "    random_state=random_state\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a2a39a8-616b-48c0-b8b1-34dd19908c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== XGB용 데이터 (category 제거) =====\n",
    "train_xgb = train.copy()\n",
    "test_xgb = test.copy()\n",
    "\n",
    "train_xgb['zipcode'] = train_xgb['zipcode'].astype(int)\n",
    "test_xgb['zipcode'] = test_xgb['zipcode'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "813b0db3-d2dd-48b4-8a8b-95f38f639225",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=500,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=random_state,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74e7e4e9-cdda-44f3-9a31-0ddade17f8a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002488 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3237\n",
      "[LightGBM] [Info] Number of data points in the train set: 15035, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 13.048122\n"
     ]
    }
   ],
   "source": [
    "# ===== Ensemble Training =====\n",
    "\n",
    "# LGBM\n",
    "lgbm_model = model\n",
    "\n",
    "lgbm_model.fit(train, y)\n",
    "xgb_model.fit(train_xgb, y)\n",
    "\n",
    "lgbm_pred = lgbm_model.predict(test)\n",
    "xgb_pred = xgb_model.predict(test_xgb)\n",
    "\n",
    "# 가중 평균 (안전한 기본값)\n",
    "ensemble_pred = 0.6 * lgbm_pred + 0.4 * xgb_pred\n",
    "\n",
    "# log -> 원래 price\n",
    "ensemble_pred = np.expm1(ensemble_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09ecd1ce-f777-417c-bd3c-abe1a3db7f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble submission saved!\n"
     ]
    }
   ],
   "source": [
    "submission = pd.read_csv(\"data/sample_submission.csv\")\n",
    "submission['price'] = ensemble_pred\n",
    "\n",
    "submission.to_csv(\n",
    "    \"data/ensemble_submission_lgbm_xgb.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"Ensemble submission saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1619739-30ea-4eb2-9457-30017ba6cf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_submission(model, train, y, test, model_name, rmsle=None):\n",
    "    model.fit(train, y)\n",
    "    prediction = model.predict(test)\n",
    "    prediction = np.expm1(prediction)\n",
    "    data_dir = '~/work/kaggle_kakr_housing/data'\n",
    "    submission_path = join(data_dir, 'sample_submission.csv')\n",
    "    submission = pd.read_csv(submission_path)\n",
    "    submission['price'] = prediction\n",
    "    submission_csv_path = '{}/submission_{}_RMSLE_{}.csv'.format(data_dir, model_name, rmsle)\n",
    "    submission.to_csv(submission_csv_path, index=False)\n",
    "    print('{} saved!'.format(submission_csv_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86e60e6d-a7fb-4ee0-9fc3-d3a087b61354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os \n",
    "# from os.path import join\n",
    "# save_submission(model, train, y, test, 'lgbm', rmsle='4')"
   ]
  },
  {
   "attachments": {
    "e6bc48c0-5f21-4afa-a13d-7cf9c367416d.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "c81cf224-4f08-4485-917f-27aaac9db95a",
   "metadata": {},
   "source": [
    "![image.png](attachment:e6bc48c0-5f21-4afa-a13d-7cf9c367416d.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
